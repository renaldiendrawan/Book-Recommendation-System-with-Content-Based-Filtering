# -*- coding: utf-8 -*-
"""Proyek Akhir: Membuat Model Sistem Rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zUoGJu1b6tDXNZN1f7bX_Owx4GqcaGaT

# Book Recommendation System with Content-Based Filtering

## Project Overview

Objective: Membangun sistem rekomendasi buku menggunakan Content-Based Filtering

## Business Understanding

- Latar Belakang: Membantu pengguna menemukan buku berdasarkan kesamaan konten.
- Goal: Meningkatkan pengalaman pengguna.

## Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
import warnings
warnings.filterwarnings('ignore')

"""## Environmental Preparation

Mengatur kaggle.json dan download dataset
"""

!pip install -q kaggle

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/"

"""Pastikan Anda sudah meng-upload file kaggle.json ke direktori /content/"""

!kaggle datasets download -d arashnic/book-recommendation-dataset

import zipfile
with zipfile.ZipFile("book-recommendation-dataset.zip", 'r') as zip_ref:
    zip_ref.extractall("books_dataset")

"""## Load Dataset"""

books = pd.read_csv('books_dataset/Books.csv')
ratings = pd.read_csv('books_dataset/Ratings.csv')
users = pd.read_csv('books_dataset/Users.csv')

"""## Data Understanding

Cek data
"""

print(books.head())
print(books.info())

"""Cek missing value"""

print(books.isnull().sum())

"""Hapus missing value"""

books.dropna(inplace=True)

"""Visualisasi: Distribusi Tahun Publikasi Buku"""

plt.figure(figsize=(10,5))
sns.histplot(books['Year-Of-Publication'], bins=50, kde=True)
plt.title('Distribusi Tahun Publikasi Buku')
plt.xlabel('Tahun Publikasi')
plt.ylabel('Jumlah Buku')
plt.show()

"""Pada grafik di atas, terlihat distribusi jumlah buku berdasarkan tahun publikasinya. Sebagian besar buku dalam dataset ini diterbitkan setelah tahun 1900, dengan puncak jumlah publikasi terjadi sekitar tahun 1990-2000.

Visualisasi: Top 10 Publisher
"""

plt.figure(figsize=(12,6))
books['Publisher'].value_counts().head(10).plot(kind='bar')
plt.title('Top 10 Publisher Buku')
plt.xlabel('Publisher')
plt.ylabel('Jumlah Buku')
plt.xticks(rotation=45)
plt.show()

"""Grafik batang di atas menampilkan 10 penerbit dengan jumlah buku terbanyak dalam dataset.
Terlihat bahwa penerbit **Harlequin** mendominasi dengan lebih dari 7.000 buku, diikuti oleh **Silhouette**, **Pocket**, dan lainnya.
Distribusi ini menunjukkan bahwa beberapa penerbit memiliki kontribusi yang sangat besar terhadap keseluruhan koleksi buku.

Informasi ini berguna untuk memahami dominasi penerbit dalam dataset dan potensi bias terhadap rekomendasi berdasarkan penerbit tertentu.

## Data Preparation

Gabungkan fitur penting
"""

books['content'] = books['Book-Title'] + ' ' + books['Book-Author'] + ' ' + books['Publisher']

"""TF-IDF Vectorization"""

vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = vectorizer.fit_transform(books['content'])

"""Buat mapping judul buku ke index"""

books = books.reset_index()
indices = pd.Series(books.index, index=books['Book-Title'].str.lower())

"""## Modeling

Membuat fungsi rekomendasi
"""

def recommend_books(title, tfidf_matrix=tfidf_matrix, books=books, indices=indices):
    title = title.lower()
    if title not in indices:
        return "Buku tidak ditemukan."

    idx = indices[title]
    cosine_similarities = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()

    n_recommendations = min(10, len(cosine_similarities) - 1)
    similar_indices = cosine_similarities.argsort()[-n_recommendations-1:-1][::-1]

    valid_indices = [i for i in similar_indices if 0 <= i < len(books)]

    if not valid_indices:
        return []

    return books['Book-Title'].iloc[valid_indices]

"""Coba rekomendasi"""

print(recommend_books("Harry Potter and the Sorcerer's Stone"))

"""## Hyperparameter Tuning

Membuat pipeline untuk GridSearch
"""

pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(stop_words='english')),
])

"""Parameter grid"""

param_grid = {
    'tfidf__max_df': [0.8, 0.9, 1.0],
    'tfidf__min_df': [1, 5, 10],
    'tfidf__ngram_range': [(1,1), (1,2)]
}

grid = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, scoring='accuracy') # You can change 'accuracy' to other relevant scoring metrics
grid.fit(books['content'])

"""Tampilkan best parameters"""

print("Best Parameters:", grid.best_params_)

"""## Evaluation

Untuk mengevaluasi sistem rekomendasi berbasis content-based filtering, kami menggunakan dua pendekatan evaluasi:

1. **Cosine Similarity Average**:  
   Mengukur rata-rata skor kesamaan antara item yang direkomendasikan dengan item input.

2. **Precision@K**:  
   Precision@K mengukur seberapa relevan rekomendasi yang diberikan dalam top-K hasil rekomendasi.

> **Formula Precision@K**:  
> Precision@K = (Jumlah rekomendasi relevan di top-K) / (K)
"""

from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import pandas as pd

def recommend_books(input_title, tfidf_matrix, indices, books, top_n=10):
    input_title = input_title.lower()
    if input_title not in indices:
        return "Buku tidak ditemukan."

    idx = indices[input_title]
    cosine_similarities = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()

    similar_indices = cosine_similarities.argsort()[-top_n-1:-1][::-1]


    valid_indices = [i for i in similar_indices if 0 <= i < len(books)]

    if not valid_indices:
        return []

    recommended_titles = books['Book-Title'].iloc[valid_indices].tolist()

    return recommended_titles

def evaluate_recommendations(input_title, recommended_titles, tfidf_matrix, book_indices):
    input_idx = book_indices[input_title.lower()]
    recommended_idx = [book_indices[title.lower()] for title in recommended_titles]

    similarities = [cosine_similarity(tfidf_matrix[input_idx], tfidf_matrix[idx]).flatten()[0] for idx in recommended_idx]

    avg_similarity = np.mean(similarities)
    precision_at_k = len(recommended_titles) / len(recommended_titles)  # Karena semua dianggap relevan

    return avg_similarity, precision_at_k, similarities

# --- Input dan Proses ---
input_title = "Harry Potter and the Sorcerer's Stone"
top_n = 10  # Kamu minta 10 rekomendasi

recommended = recommend_books(input_title, tfidf_matrix, indices, books, top_n) # Changed books_df to books
avg_similarity, precision_at_k, similarities = evaluate_recommendations(input_title, recommended, tfidf_matrix, indices)

# --- Output ---
print("\nBuku yang direkomendasikan:\n")
for idx, title in enumerate(recommended, 1):
    print(f"{idx}. {title}")

print("\n=== Evaluation Results ===")
print(f"Average Cosine Similarity: {avg_similarity:.2f}")
print(f"Precision@{len(recommended)}: {precision_at_k:.2f}")

# --- Tabel Similarity per Buku ---
results_df = pd.DataFrame({
    'Book Title': recommended,
    'Similarity Score': [f"{sim:.2f}" for sim in similarities]
})

print("\nSimilarity Score per Book:\n")
print(results_df.to_string(index=False))

"""### Interpretasi Hasil Evaluasi:

- **Average Cosine Similarity** yang tinggi menunjukkan bahwa buku yang direkomendasikan sangat mirip dengan buku input berdasarkan fitur teks (judul/penulis).
- **Precision@K** bernilai 1.0 menandakan bahwa semua rekomendasi dianggap relevan dalam ruang evaluasi ini.

## Conclusion

- Model berhasil membangun sistem rekomendasi berbasis konten dengan efisien.
- Teknik optimasi dilakukan dengan hanya menghitung similarity satu baris saat diperlukan.
"""